先估算数据的大致量级。

粗略的计算：1K==》千，1M==》百万，1G==》10亿。这个对于海量数据差距算是小的。

一般40亿数据，计算机表示就是4G的entry实体。*这里的entry是我的一种叫法，比如使用bit表示一个实体就是4G的bit==》0.5GB*。



然后采用，TOPK，hash，分治，trie，Bloom Filter这些。





### 大致的思路

> **这些都没啥用**
>
> 在面试中，处理海量数据的问题是常见的考点之一。以下是一些常见的海量数据问题及其处理思路：
>
> 1. 统计海量数据中的热门词汇
>
> 处理思路： 可以使用哈希表和堆排序。首先，使用哈希表对每个单词进行计数，然后将它们插入到一个最小堆中，最小堆中只保留前 K 个出现频率最高的单词。
>
> 1. 查找海量数据中的重复元素
>
> 处理思路： 可以使用哈希表和位图法。首先，将每个元素都哈希到对应的桶中，并在哈希冲突时使用链表来解决。然后，使用位图法标记每个桶中是否有重复元素。最后，遍历所有的桶，输出包含重复元素的桶中的元素。
>
> 1. 查找海量数据中的中位数
>
> 处理思路： 可以使用堆排序或分治法。如果数据量较小，可以使用堆排序来找到中位数。如果数据量非常大，可以使用分治法，将海量数据划分为多个小数据集，然后找到每个小数据集的中位数，再使用递归的方式，最终找到整个数据集的中位数。
>
> 1. 计算海量数据的倒排索引
>
> 处理思路： 可以使用哈希表和倒排索引。首先，将每个文档都分词，并将每个词语的出现位置记录在倒排索引表中。然后，使用哈希表将每个词语的倒排索引表关联到该词语上。最后，可以通过查询哈希表来查找包含特定词语的文档。
>
> 1. 对海量数据进行排序
>
> 处理思路： 可以使用外部排序算法，如归并排序或快速排序。外部排序算法适用于无法一次性将所有数据加载到内存中的情况。外部排序算法将数据分成多个小块，并对每个小块进行排序，然后使用归并排序将它们合并成一个有序序列。

在面试中，常常会遇到需要处理海量数据的问题，这些问题可能包括：

1. 如何在海量数据中查找某个元素？哈希表，大文件分割成小文件，哈希值相同的放在同一个文件；bitMap，布隆过滤器，特别是对于字符串来说可以使用trie树。
2. 如何对海量数据进行排序？这个外排序，具体不会
3. 如何对海量数据进行去重？
4. 如何在海量数据中进行数据分析？

下面是一些处理海量数据问题的解答方法：

1. 使用分治法或哈希表。对于需要查找某个元素的问题，可以将数据分成多个部分，分别进行查找，最后合并结果。另外，哈希表也是一种有效的数据结构，可以用于快速查找数据。

   大文件划分为小文件，hash值相同的放在同一个小文件。eg：100G的文件，内存4G；所以可以分为25个文件，使用哈希值mod25放入相应的桶里面。

2. 使用外部排序。对于需要排序的问题，可以使用外部排序算法，例如归并排序和快速排序，这些算法可以有效地处理大量数据。

3. 使用哈希表或位图。对于需要去重的问题，可以使用哈希表或位图来记录已经出现过的元素，从而去除重复的数据。bitmap/bloom filter

4. 使用MapReduce或Spark。对于需要进行数据分析的问题，可以使用分布式计算框架，例如MapReduce或Spark，这些框架可以有效地处理大量数据，实现并行计算。

无论遇到什么海量数据问题，都可以通过划分数据，使用适当的数据结构和算法，以及分布式计算等技术来解决。同时，在处理海量数据问题时，需要考虑时间和空间的复杂度，并尽可能优化算法，以获得更好的效率。



常用的数据结构，哈希表，trie树（字符串树），布隆过滤器，分布式计算框架。



### 例题一，海量查找

设计一个目标字符串查询系统，输入一个目标字符串，找出磁盘上40亿个字符串中和目标字符串完全匹配的字符串，可以对40亿个字符串（数据量> 100GB 服务器可用内存为8GB）进行预处理，

（1）如果目标是**尽可能快**的完成字符串搜索工作，应该如何设计。

（2）如果不仅需要找到目标字符串还需要返回**按字典序**排在该字符串后面的字符串数量，又该如何设计呢？（字典序即字符串按照字母A-Z升序排列）



>**方法一使用布隆过滤器** 布隆过滤器好通用啊，学习一下。  前提40亿使用0.5GB内存的bit就足够指示每一个实体了。由此可见，即使80亿数据8G内存足够。==》重算：40亿==》4G的bit==》0.5G的字节，只需记住40亿==》4G。    但是这东西的误判断怎么办？
>
>针对这个问题，可以使用一种称为Bloom Filter的数据结构进行预处理。Bloom Filter是一种空间高效的概率数据结构，可用于快速检索字符串是否存在于一个大型集合中。它将字符串映射到一个比特数组中，并使用多个哈希函数来决定哪些位置应该被设置为1。在查询时，如果所有的哈希函数都指示一个位置被设置为1，那么可以高度确信字符串存在于集合中；如果任何一个哈希函数指示一个位置被设置为0，那么字符串不存在于集合中。（布隆过滤器，可以指定失误率，这个怎么办？）
>
>具体而言，可以将40亿个字符串分成多个小文件，并使用Bloom Filter预处理每个文件。然后，对于目标字符串，可以将其哈希到相应的Bloom Filter中，并检查每个哈希函数指示的位置是否都为1。如果是，则在相应的文件中查找该字符串以获取确切的匹配项。由于Bloom Filter的空间效率很高，因此可以使用相对较小的内存来处理40亿个字符串，而且由于使用了哈希函数，可以减少磁盘访问的数量，从而加速搜索过程。
>
>对于第二个问题，可以在Bloom Filter中存储每个字符串的哈希值，并将哈希值存储在排序数组中。然后，可以使用二分查找算法在排序数组中查找目标字符串的哈希值，并返回在该哈希值之后的字符串数量。这将需要使用更多的内存来存储排序数组，但可以在不打破内存限制的情况下处理附加要求。
>
>值得注意的是，Bloom Filter具有一定的误报率，即某些不存在的字符串可能会被误认为存在。因此，在查询时，必须使用确切的匹配来验证任何Bloom Filter返回的匹配项。同时，Bloom Filter的性能取决于哈希函数的选择，因此需要进行一些实验来选择最适合数据集的哈希函数。





>**方法二，分别使用hash和trie树**      
>
>## 基于哈希表的方案
>
>如何分析时空复杂度？这不会分析啊。hash表里面存的是`pair<key,value>` 空间复杂度增加。
>
>题目得告诉你能不能放入内存
>
>### 预处理
>
>为了快速查找，我们可以将40亿个字符串建立哈希表，其中哈希表的键为字符串，值为字符串出现的次数。建立哈希表需要遵循以下步骤：
>
>1. 读取每个字符串
>2. 对每个字符串计算哈希值
>3. 将哈希值作为键插入哈希表中，值为1
>4. 如果该哈希值已经存在，增加对应键的值
>
>在此过程中，需要考虑哈希值冲突的情况。常见的解决哈希冲突的方法包括链式哈希和开放寻址法。
>
>### 查找
>
>对于输入的目标字符串，我们可以直接在哈希表中查找是否存在该字符串，如果存在，则输出该字符串，否则输出“未找到”。
>
>### 优化
>
>由于内存只有8GB，我们需要将哈希表放入磁盘中，可以使用外部哈希表。另外，如果哈希表太大无法一次性加载到内存中，我们可以分割成多个文件，每个文件包含一部分哈希表。当查询时，只需要加载相关文件即可。具体：根据文件的大小，划分为几个小文件，把hash值相同的放在同一个小文件。
>
>## 基于Trie树的方案
>
>### 预处理
>
>我们可以将40亿个字符串建立Trie树。Trie树是一种树形数据结构，它将每个字符串存储在树中，并且每个节点代表一个字符。对于每个节点，它的子节点代表该节点字符后面所有可能的字符。
>
>在构建Trie树时，我们需要遵循以下步骤：
>
>1. 读取每个字符串
>2. 对每个字符串的每个字符，从根节点开始，按字符顺序往下遍历Trie树，并在相应位置插入新节点
>3. 在每个字符串最后一个字符所在节点上标记字符串结束的标志
>
>### 查找
>
>对于输入的目标字符串，我们可以在Trie树上遍历，找到最后一个字符所在节点，检查该节点是否标记了字符串结束的标志。如果标记了，说明目标字符串存在于Trie树中，否则输出“未找到”。
>
>### 优化
>
>由于内存限制，我们需要将Trie树放入磁盘中。可以使用基于磁盘的Trie树。基于磁盘的Trie树将Trie树分割成多个部分，并将每个部分存储在磁盘上。每个节点都包含一个指向子节点的指针，该指针指向下一部分所在的磁盘块。查询时，只需要加载相关部分即可。





### top K问题

1、求最大的/最小的前K个元素 ==》求最大的就使用小根堆

​	步骤：遇到比top大的就把堆顶换掉，然后调整。

​	求最小的k个就使用大根堆，每次剔除最大的。

2、求最大/最小的第K个元素。

​	得到最大的前k个之后进行每次pop即可取到目标值。



### 访问次数最多的IP

 海量日志数据，提取出访问次数最多的IP。

IP32位==》40亿。也就是4G的entry，一个IP用4字节表示的话==》16GB。

*海量数据前提基本都是内存不够*     这里题目有问题，不知道内存大小&文件大小。

其实估算后就好想了。



